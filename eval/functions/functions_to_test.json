[
  {
    "name": "get_auth_from_url",
    "module": "requests.utils",
    "file": "requests/src/requests/utils.py",
    "qualname": "requests.utils.get_auth_from_url",
    "imports": [
      "import codecs",
      "import contextlib",
      "import io",
      "import os",
      "import re",
      "import socket",
      "import struct",
      "import sys",
      "import tempfile",
      "import warnings",
      "import zipfile",
      "from collections import OrderedDict",
      "",
      "from urllib3.util import make_headers, parse_url",
      "",
      "from . import certs",
      "from .__version__ import __version__",
      "",
      "# to_native_string is unused here, but imported here for backwards compatibility",
      "from ._internal_utils import (  # noqa: F401",
      "    _HEADER_VALIDATORS_BYTE,",
      "    _HEADER_VALIDATORS_STR,",
      "    HEADER_VALIDATORS,",
      "    to_native_string,",
      ")",
      "from .compat import (",
      "    Mapping,",
      "    basestring,",
      "    bytes,",
      "    getproxies,",
      "    getproxies_environment,",
      "    integer_types,",
      "    is_urllib3_1,",
      ")",
      "from .compat import parse_http_list as _parse_list_header",
      "from .compat import (",
      "    proxy_bypass,",
      "    proxy_bypass_environment,",
      "    quote,",
      "    str,",
      "    unquote,",
      "    urlparse,",
      "    urlunparse,",
      ")",
      "from .cookies import cookiejar_from_dict",
      "from .exceptions import (",
      "    FileModeWarning,",
      "    InvalidHeader,",
      "    InvalidURL,",
      "    UnrewindableBodyError,",
      ")",
      "from .structures import CaseInsensitiveDict",
      "",
      "NETRC_FILES = (\".netrc\", \"_netrc\")",
      "",
      "DEFAULT_CA_BUNDLE_PATH = certs.where()",
      "",
      "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}",
      "",
      "# Ensure that ', ' is used to preserve previous delimiter behavior.",
      "DEFAULT_ACCEPT_ENCODING = \", \".join(",
      "    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "urlparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlparse(url, scheme='', allow_fragments=True):",
          "    \"\"\"Parse a URL into 6 components:",
          "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
          "",
          "    The result is a named 6-tuple with fields corresponding to the",
          "    above. It is either a ParseResult or ParseResultBytes object,",
          "    depending on the type of the url parameter.",
          "",
          "    The username, password, hostname, and port sub-components of netloc",
          "    can also be accessed as attributes of the returned object.",
          "",
          "    The scheme argument provides the default value of the scheme",
          "    component when no scheme is found in url.",
          "",
          "    If allow_fragments is False, no attempt is made to separate the",
          "    fragment component from the previous component, which can be either",
          "    path or query.",
          "",
          "    Note that % escapes are not expanded.",
          "    \"\"\"",
          "    url, scheme, _coerce_result = _coerce_args(url, scheme)",
          "    splitresult = urlsplit(url, scheme, allow_fragments)",
          "    scheme, netloc, url, query, fragment = splitresult",
          "    if scheme in uses_params and ';' in url:",
          "        url, params = _splitparams(url)",
          "    else:",
          "        params = ''",
          "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
          "    return _coerce_result(result)"
        ]
      },
      {
        "id": 2,
        "dependency_name": "unquote",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "requests/src/requests/compat.py",
        "dependency_function_def": [
          "def unquote(string, encoding='utf-8', errors='replace'):",
          "    \"\"\"Replace %xx escapes by their single-character equivalent. The optional",
          "    encoding and errors parameters specify how to decode percent-encoded",
          "    sequences into Unicode characters, as accepted by the bytes.decode()",
          "    method.",
          "    By default, percent-encoded sequences are decoded with UTF-8, and invalid",
          "    sequences are replaced by a placeholder character.",
          "",
          "    unquote('abc%20def') -> 'abc def'.",
          "    \"\"\"",
          "    if isinstance(string, bytes):",
          "        return _unquote_impl(string).decode(encoding, errors)",
          "    if '%' not in string:",
          "        # Is it a string-like object?",
          "        string.split",
          "        return string",
          "    if encoding is None:",
          "        encoding = 'utf-8'",
          "    if errors is None:",
          "        errors = 'replace'",
          "    return ''.join(_generate_unquoted_parts(string, encoding, errors))"
        ]
      }
    ],
    "function_def": [
      "def get_auth_from_url(url):",
      "    \"\"\"Given a url with authentication components, extract them into a tuple of",
      "    username,password.",
      "",
      "    :rtype: (str,str)",
      "    \"\"\"",
      "    parsed = urlparse(url)",
      "",
      "    try:",
      "        auth = (unquote(parsed.username), unquote(parsed.password))",
      "    except (AttributeError, TypeError):",
      "        auth = (\"\", \"\")",
      "",
      "    return auth"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_get_auth_from_url",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::test_get_auth_from_url",
        "test_code": [
          "USER = PASSWORD = \"%!*'();:@&=+$,/?#[] \"",
          "ENCODED_USER = compat.quote(USER, \"\")",
          "ENCODED_PASSWORD = compat.quote(PASSWORD, \"\")",
          "",
          "@pytest.mark.parametrize(",
          "    \"url, auth\",",
          "    (",
          "        (",
          "            f\"http://{ENCODED_USER}:{ENCODED_PASSWORD}@request.com/url.html#test\",",
          "            (USER, PASSWORD),",
          "        ),",
          "        (\"http://user:pass@complex.url.com/path?query=yes\", (\"user\", \"pass\")),",
          "        (\"http://user:pass%20pass@complex.url.com/path?query=yes\", (\"user\", \"pass pass\")),",
          "        (\"http://user:pass pass@complex.url.com/path?query=yes\", (\"user\", \"pass pass\")),",
          "        (\"http://user%25user:pass@complex.url.com/path?query=yes\", (\"user%user\", \"pass\")),",
          "        (\"http://user:pass%23pass@complex.url.com/path?query=yes\", (\"user\", \"pass#pass\")),",
          "        (\"http://complex.url.com/path?query=yes\", (\"\", \"\")),",
          "    ),",
          ")",
          "def test_get_auth_from_url(url, auth):",
          "    assert get_auth_from_url(url) == auth"
        ]
      }
    ],
    "fixtures": [],
    "description": "Extract username and password from a URL, decoding percent-encoded components. Returns ('', '') when no credentials present or when parsed attributes are missing.",
    "security_focus": [
      "credential_handling",
      "percent_encoding_handling",
      "sensitive_output_disclosure"
    ],
    "setup_notes": {
      "note": "Pure unit test; no network or heavy fixtures required. The test uses compat.quote to prepare encoded username/password examples. When sending to an LLM, include the parametrization examples so the model sees varied encoded and edge-case inputs."
    }
  },
  {
    "name": "prepend_scheme_if_needed",
    "module": "requests.utils",
    "file": "requests/src/requests/utils.py",
    "qualname": "requests.utils.prepend_scheme_if_needed",
    "imports": [
      "import codecs",
      "import contextlib",
      "import io",
      "import os",
      "import re",
      "import socket",
      "import struct",
      "import sys",
      "import tempfile",
      "import warnings",
      "import zipfile",
      "from collections import OrderedDict",
      "",
      "from urllib3.util import make_headers, parse_url",
      "",
      "from . import certs",
      "from .__version__ import __version__",
      "",
      "# to_native_string is unused here, but imported here for backwards compatibility",
      "from ._internal_utils import (  # noqa: F401",
      "    _HEADER_VALIDATORS_BYTE,",
      "    _HEADER_VALIDATORS_STR,",
      "    HEADER_VALIDATORS,",
      "    to_native_string,",
      ")",
      "from .compat import (",
      "    Mapping,",
      "    basestring,",
      "    bytes,",
      "    getproxies,",
      "    getproxies_environment,",
      "    integer_types,",
      "    is_urllib3_1,",
      ")",
      "from .compat import parse_http_list as _parse_list_header",
      "from .compat import (",
      "    proxy_bypass,",
      "    proxy_bypass_environment,",
      "    quote,",
      "    str,",
      "    unquote,",
      "    urlparse,",
      "    urlunparse,",
      ")",
      "from .cookies import cookiejar_from_dict",
      "from .exceptions import (",
      "    FileModeWarning,",
      "    InvalidHeader,",
      "    InvalidURL,",
      "    UnrewindableBodyError,",
      ")",
      "from .structures import CaseInsensitiveDict",
      "",
      "NETRC_FILES = (\".netrc\", \"_netrc\")",
      "",
      "DEFAULT_CA_BUNDLE_PATH = certs.where()",
      "",
      "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}",
      "",
      "# Ensure that ', ' is used to preserve previous delimiter behavior.",
      "DEFAULT_ACCEPT_ENCODING = \", \".join(",
      "    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "parse_url",
        "dependency_module": "urllib3.util.url",
        "dependency_file": "lib/python3.12/site-packages/urllib3/util/url.py",
        "imported_via_module": "urllib3.util",
        "imported_via_file": "lib/python3.12/site-packages/urllib3/util/__init__.py",
        "dependency_function_def": [
          "def parse_url(url: str) -> Url:",
          "    \"\"\"",
          "    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is",
          "    performed to parse incomplete urls. Fields not provided will be None.",
          "    This parser is RFC 3986 and RFC 6874 compliant.",
          "",
          "    The parser logic and helper functions are based heavily on",
          "    work done in the ``rfc3986`` module.",
          "",
          "    :param str url: URL to parse into a :class:`.Url` namedtuple.",
          "",
          "    Partly backwards-compatible with :mod:`urllib.parse`.",
          "",
          "    Example:",
          "",
          "    .. code-block:: python",
          "",
          "        import urllib3",
          "",
          "        print( urllib3.util.parse_url('http://google.com/mail/'))",
          "        # Url(scheme='http', host='google.com', port=None, path='/mail/', ...)",
          "",
          "        print( urllib3.util.parse_url('google.com:80'))",
          "        # Url(scheme=None, host='google.com', port=80, path=None, ...)",
          "",
          "        print( urllib3.util.parse_url('/foo?bar'))",
          "        # Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)",
          "    \"\"\"",
          "    if not url:",
          "        # Empty",
          "        return Url()",
          "",
          "    source_url = url",
          "    if not _SCHEME_RE.search(url):",
          "        url = \"//\" + url",
          "",
          "    scheme: str | None",
          "    authority: str | None",
          "    auth: str | None",
          "    host: str | None",
          "    port: str | None",
          "    port_int: int | None",
          "    path: str | None",
          "    query: str | None",
          "    fragment: str | None",
          "",
          "    try:",
          "        scheme, authority, path, query, fragment = _URI_RE.match(url).groups()  # type: ignore[union-attr]",
          "        normalize_uri = scheme is None or scheme.lower() in _NORMALIZABLE_SCHEMES",
          "",
          "        if scheme:",
          "            scheme = scheme.lower()",
          "",
          "        if authority:",
          "            auth, _, host_port = authority.rpartition(\"@\")",
          "            auth = auth or None",
          "            host, port = _HOST_PORT_RE.match(host_port).groups()  # type: ignore[union-attr]",
          "            if auth and normalize_uri:",
          "                auth = _encode_invalid_chars(auth, _USERINFO_CHARS)",
          "            if port == \"\":",
          "                port = None",
          "        else:",
          "            auth, host, port = None, None, None",
          "",
          "        if port is not None:",
          "            port_int = int(port)",
          "            if not (0 <= port_int <= 65535):",
          "                raise LocationParseError(url)",
          "        else:",
          "            port_int = None",
          "",
          "        host = _normalize_host(host, scheme)",
          "",
          "        if normalize_uri and path:",
          "            path = _remove_path_dot_segments(path)",
          "            path = _encode_invalid_chars(path, _PATH_CHARS)",
          "        if normalize_uri and query:",
          "            query = _encode_invalid_chars(query, _QUERY_CHARS)",
          "        if normalize_uri and fragment:",
          "            fragment = _encode_invalid_chars(fragment, _FRAGMENT_CHARS)",
          "",
          "    except (ValueError, AttributeError) as e:",
          "        raise LocationParseError(source_url) from e",
          "",
          "    # For the sake of backwards compatibility we put empty",
          "    # string values for path if there are any defined values",
          "    # beyond the path in the URL.",
          "    # TODO: Remove this when we break backwards compatibility.",
          "    if not path:",
          "        if query is not None or fragment is not None:",
          "            path = \"\"",
          "        else:",
          "            path = None",
          "",
          "    return Url(",
          "        scheme=scheme,",
          "        auth=auth,",
          "        host=host,",
          "        port=port_int,",
          "        path=path,",
          "        query=query,",
          "        fragment=fragment,",
          "    )"
        ]
      },
      {
        "id": 2,
        "dependency_name": "urlunparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlunparse(components):",
          "    \"\"\"Put a parsed URL back together again.  This may result in a",
          "    slightly different, but equivalent URL, if the URL that was parsed",
          "    originally had redundant delimiters, e.g. a ? with an empty query",
          "    (the draft states that these are equivalent).\"\"\"",
          "    scheme, netloc, url, params, query, fragment, _coerce_result = (",
          "                                                  _coerce_args(*components))",
          "    if params:",
          "        url = \"%s;%s\" % (url, params)",
          "    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))"
        ]
      }
    ],
    "function_def": [
      "def prepend_scheme_if_needed(url, new_scheme):",
      "    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.",
      "    Does not replace a present scheme with the one provided as an argument.",
      "",
      "    :rtype: str",
      "    \"\"\"",
      "    parsed = parse_url(url)",
      "    scheme, auth, host, port, path, query, fragment = parsed",
      "",
      "    # A defect in urlparse determines that there isn't a netloc present in some",
      "    # urls. We previously assumed parsing was overly cautious, and swapped the",
      "    # netloc and path. Due to a lack of tests on the original defect, this is",
      "    # maintained with parse_url for backwards compatibility.",
      "    netloc = parsed.netloc",
      "    if not netloc:",
      "        netloc, path = path, netloc",
      "",
      "    if auth:",
      "        # parse_url doesn't provide the netloc with auth",
      "        # so we'll add it ourselves.",
      "        netloc = \"@\".join([auth, netloc])",
      "    if scheme is None:",
      "        scheme = new_scheme",
      "    if path is None:",
      "        path = \"\"",
      "",
      "    return urlunparse((scheme, netloc, path, \"\", query, fragment))"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_prepend_scheme_if_needed",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::test_prepend_scheme_if_needed",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"value, expected\",",
          "    (",
          "        (\"example.com/path\", \"http://example.com/path\"),",
          "        (\"//example.com/path\", \"http://example.com/path\"),",
          "        (\"example.com:80\", \"http://example.com:80\"),",
          "        (\"http://user:pass@example.com/path?query\", \"http://user:pass@example.com/path?query\"),",
          "        (\"http://user@example.com/path?query\", \"http://user@example.com/path?query\"),",
          "    ),",
          ")",
          "def test_prepend_scheme_if_needed(value, expected):",
          "    assert prepend_scheme_if_needed(value, \"http\") == expected"
        ]
      }
    ],
    "fixtures": [],
    "description": "Ensure a scheme (e.g., 'http') is prepended when missing; preserve existing scheme, auth, host, port, path and query. Handles protocol-relative URLs and cases where parse_url may swap netloc/path.",
    "security_focus": [
      "url_canonicalization",
      "credential_handling (preserve/remove auth as appropriate)",
      "sensitive_output_disclosure"
    ],
    "setup_notes": {
      "note": "Unit tests in test_utils.py are self-contained; include parametrized examples so the LLM sees protocol-relative, existing-scheme, and auth-containing cases. No network fixtures required."
    }
  },
  {
    "name": "_basic_auth_str",
    "module": "requests.auth",
    "file": "requests/src/requests/auth.py",
    "qualname": "requests.auth._basic_auth_str",
    "imports": [
      "import hashlib",
      "import os",
      "import re",
      "import threading",
      "import time",
      "import warnings",
      "from base64 import b64encode",
      "",
      "from ._internal_utils import to_native_string",
      "from .compat import basestring, str, urlparse",
      "from .cookies import extract_cookies_to_jar",
      "from .utils import parse_dict_header",
      "",
      "CONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"",
      "CONTENT_TYPE_MULTI_PART = \"multipart/form-data\""
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "to_native_string",
        "dependency_module": "requests._internal_utils",
        "dependency_file": "requests/src/requests/_internal_utils.py",
        "imported_via_module": "requests._internal_utils",
        "imported_via_file": "requests/src/requests/_internal_utils.py",
        "dependency_function_def": [
          "def to_native_string(string, encoding='utf-8'):",
          "    if isinstance(string, bytes):",
          "        return string.decode(encoding)",
          "    return string"
        ]
      },
      {
        "id": 2,
        "dependency_name": "b64encode",
        "dependency_module": "base64",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/base64.py",
        "imported_via_module": "base64",
        "imported_via_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/base64.py",
        "dependency_function_def": [
          "def b64encode(s, altchars=None):",
          "    \"\"\"Encode a bytes-like object using Base64 and return bytes.\"\"\"",
          "    import binascii",
          "    if altchars is not None:",
          "        return binascii.b2a_base64(s).rstrip(b'\\n').translate(_urlsafe_encode_translation(altchars))",
          "    return binascii.b2a_base64(s).rstrip(b'\\n')"
        ]
      }
    ],
    "function_def": [
      "def _basic_auth_str(username, password):",
      "    \"\"\"Returns a Basic Auth string.\"\"\"",
      "",
      "    # \"I want us to put a big-ol' comment on top of it that",
      "    # says that this behaviour is dumb but we need to preserve",
      "    # it because people are relying on it.\"",
      "    #    - Lukasa",
      "    #",
      "    # These are here solely to maintain backwards compatibility",
      "    # for things like ints. This will be removed in 3.0.0.",
      "    if not isinstance(username, basestring):",
      "        warnings.warn(",
      "            \"Non-string usernames will no longer be supported in Requests \"",
      "            \"3.0.0. Please convert the object you've passed in ({!r}) to \"",
      "            \"a string or bytes object in the near future to avoid \"",
      "            \"problems.\".format(username),",
      "            category=DeprecationWarning,",
      "        )",
      "        username = str(username)",
      "",
      "    if not isinstance(password, basestring):",
      "        warnings.warn(",
      "            \"Non-string passwords will no longer be supported in Requests \"",
      "            \"3.0.0. Please convert the object you've passed in ({!r}) to \"",
      "            \"a string or bytes object in the near future to avoid \"",
      "            \"problems.\".format(type(password)),",
      "            category=DeprecationWarning,",
      "        )",
      "        password = str(password)",
      "    # -- End Removal --",
      "",
      "    if isinstance(username, str):",
      "        username = username.encode(\"latin1\")",
      "",
      "    if isinstance(password, str):",
      "        password = password.encode(\"latin1\")",
      "",
      "    authstr = \"Basic \" + to_native_string(",
      "        b64encode(b\":\".join((username, password))).strip()",
      "    )",
      "",
      "    return authstr"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_set_basicauth",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_set_basicauth",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"username, password\",",
          "    (",
          "        (\"user\", \"pass\"),",
          "        (\"имя\".encode(), \"пароль\".encode()),",
          "        (42, 42),",
          "        (None, None),",
          "    ),",
          ")",
          "def test_set_basicauth(self, httpbin, username, password):",
          "    auth = (username, password)",
          "    url = httpbin(\"get\")",
          "",
          "    r = requests.Request(\"GET\", url, auth=auth)",
          "    p = r.prepare()",
          "",
          "    assert p.headers[\"Authorization\"] == _basic_auth_str(username, password)"
        ]
      },
      {
        "id": 2,
        "test_name": "test_basic_auth_str_is_always_native",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_basic_auth_str_is_always_native",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"username, password, auth_str\",",
          "    (",
          "        (\"test\", \"test\", \"Basic dGVzdDp0ZXN0\"),",
          "        (",
          "            \"имя\".encode(),",
          "            \"пароль\".encode(),",
          "            \"Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA==\",",
          "        ),",
          "    ),",
          ")",
          "def test_basic_auth_str_is_always_native(self, username, password, auth_str):",
          "    s = _basic_auth_str(username, password)",
          "    assert isinstance(s, builtin_str)",
          "    assert s == auth_str"
        ]
      }
    ],
    "fixtures": [
      "httpbin (used by test_set_basicauth for simple HTTP endpoints)",
      "builtin_str (type alias used in tests for native/string assertions)"
    ],
    "description": "Constructs a Basic Authorization header value from username and password. Handles bytes, str, and non-string inputs (with deprecation warnings), encodes str to latin-1 bytes, base64-encodes the username:password pair and returns a native string prefixed with 'Basic '.",
    "security_focus": [
      "credential_handling",
      "sensitive_output_disclosure",
      "output_sanitization",
      "header_injection (CRLF)"
    ],
    "setup_notes": {
      "note": "The example tests reference fixtures (httpbin, builtin_str) and may rely on module-level imports/fixtures in the test suite. When sending this entry to an LLM, include a brief note asking the model to either mock those fixtures or produce self-contained tests that do not require the full test harness.",
      "recommendation": "Prefer providing minimal stubs for httpbin or instruct the LLM to use tmp_path/monkeypatch to avoid network and heavy fixtures."
    }
  },
  {
    "name": "HTTPDigestAuth",
    "module": "requests.auth",
    "file": "requests/src/requests/auth.py",
    "qualname": "requests.auth.HTTPDigestAuth",
    "imports": [
      "import hashlib",
      "import os",
      "import re",
      "import threading",
      "import time",
      "import warnings",
      "from base64 import b64encode",
      "",
      "from ._internal_utils import to_native_string",
      "from .compat import basestring, str, urlparse",
      "from .cookies import extract_cookies_to_jar",
      "from .utils import parse_dict_header",
      "",
      "CONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"",
      "CONTENT_TYPE_MULTI_PART = \"multipart/form-data\""
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "urlparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlparse(url, scheme='', allow_fragments=True):",
          "    \"\"\"Parse a URL into 6 components:",
          "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
          "",
          "    The result is a named 6-tuple with fields corresponding to the",
          "    above. It is either a ParseResult or ParseResultBytes object,",
          "    depending on the type of the url parameter.",
          "",
          "    The username, password, hostname, and port sub-components of netloc",
          "    can also be accessed as attributes of the returned object.",
          "",
          "    The scheme argument provides the default value of the scheme",
          "    component when no scheme is found in url.",
          "",
          "    If allow_fragments is False, no attempt is made to separate the",
          "    fragment component from the previous component, which can be either",
          "    path or query.",
          "",
          "    Note that % escapes are not expanded.",
          "    \"\"\"",
          "    url, scheme, _coerce_result = _coerce_args(url, scheme)",
          "    splitresult = urlsplit(url, scheme, allow_fragments)",
          "    scheme, netloc, url, query, fragment = splitresult",
          "    if scheme in uses_params and ';' in url:",
          "        url, params = _splitparams(url)",
          "    else:",
          "        params = ''",
          "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
          "    return _coerce_result(result)"
        ]
      },
      {
        "id": 2,
        "dependency_name": "Response.is_redirect",
        "dependency_module": "requests.models",
        "dependency_file": "requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "requests/src/requests/models.py",
        "dependency_function_def": [
          "@property",
          "def is_redirect(self):",
          "    \"\"\"True if this Response is a well-formed HTTP redirect that could have",
          "    been processed automatically (by :meth:`Session.resolve_redirects`).",
          "    \"\"\"",
          "    return \"location\" in self.headers and self.status_code in REDIRECT_STATI"
        ]
      },
      {
        "id": 3,
        "dependency_name": "parse_dict_header",
        "dependency_module": "requests.utils",
        "dependency_file": "requests/src/requests/utils.py",
        "imported_via_module": "requests.utils",
        "imported_via_file": "requests/src/requests/utils.py",
        "dependency_function_def": [
          "def parse_dict_header(value):",
          "    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and",
          "    convert them into a python dict:",
          "",
          "    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')",
          "    >>> type(d) is dict",
          "    True",
          "    >>> sorted(d.items())",
          "    [('bar', 'as well'), ('foo', 'is a fish')]",
          "",
          "    If there is no value for a key it will be `None`:",
          "",
          "    >>> parse_dict_header('key_without_value')",
          "    {'key_without_value': None}",
          "",
          "    To create a header from the :class:`dict` again, use the",
          "    :func:`dump_header` function.",
          "",
          "    :param value: a string with a dict header.",
          "    :return: :class:`dict`",
          "    :rtype: dict",
          "    \"\"\"",
          "    result = {}",
          "    for item in _parse_list_header(value):",
          "        if \"=\" not in item:",
          "            result[item] = None",
          "            continue",
          "        name, value = item.split(\"=\", 1)",
          "        if value[:1] == value[-1:] == '\"':",
          "            value = unquote_header_value(value[1:-1])",
          "        result[name] = value",
          "    return result"
        ]
      },
      {
        "id": 4,
        "dependency_name": "extract_cookies_to_jar",
        "dependency_module": "requests.cookies",
        "dependency_file": "requests/src/requests/cookies.py",
        "imported_via_module": "requests.cookies",
        "imported_via_file": "requests/src/requests/cookies.py",
        "dependency_function_def": [
          "def extract_cookies_to_jar(jar, request, response):",
          "    \"\"\"Extract the cookies from the response into a CookieJar.",
          "",
          "    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)",
          "    :param request: our own requests.Request object",
          "    :param response: urllib3.HTTPResponse object",
          "    \"\"\"",
          "    if not (hasattr(response, \"_original_response\") and response._original_response):",
          "        return",
          "    # the _original_response field is the wrapped httplib.HTTPResponse object,",
          "    req = MockRequest(request)",
          "    # pull out the HTTPMessage with the headers and put it in the mock:",
          "    res = MockResponse(response._original_response.msg)",
          "    jar.extract_cookies(res, req)"
        ]
      },
      {
        "id": 5,
        "dependency_name": "PreparedRequest.copy",
        "dependency_module": "requests.models",
        "dependency_file": "requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "requests/src/requests/models.py",
        "dependency_function_def": [
          "def copy(self):",
          "    p = PreparedRequest()",
          "    p.method = self.method",
          "    p.url = self.url",
          "    p.headers = self.headers.copy() if self.headers is not None else None",
          "    p._cookies = _copy_cookie_jar(self._cookies)",
          "    p.body = self.body",
          "    p.hooks = self.hooks",
          "    p._body_position = self._body_position",
          "    return p"
        ]
      },
      {
        "id": 6,
        "dependency_name": "PreparedRequest.prepare_cookies",
        "dependency_module": "requests.models",
        "dependency_file": "requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "requests/src/requests/models.py",
        "dependency_function_def": [
          "def prepare_cookies(self, cookies):",
          "    \"\"\"Prepares the given HTTP cookie data.",
          "",
          "    This function eventually generates a ``Cookie`` header from the",
          "    given cookies using cookielib. Due to cookielib's design, the header",
          "    will not be regenerated if it already exists, meaning this function",
          "    can only be called once for the life of the",
          "    :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls",
          "    to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"",
          "    header is removed beforehand.",
          "    \"\"\"",
          "    if isinstance(cookies, cookielib.CookieJar):",
          "        self._cookies = cookies",
          "    else:",
          "        self._cookies = cookiejar_from_dict(cookies)",
          "",
          "    cookie_header = get_cookie_header(self._cookies, self)",
          "    if cookie_header is not None:",
          "        self.headers[\"Cookie\"] = cookie_header"
        ]
      },
      {
        "id": 7,
        "dependency_name": "BaseAdapter.send",
        "dependency_module": "requests.adapters",
        "dependency_file": "requests/src/requests/adapters.py",
        "imported_via_module": "requests.adapters",
        "imported_via_file": "requests/src/requests/adapters.py",
        "dependency_function_def": [
          "def send(",
          "    self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None",
          "):",
          "    \"\"\"Sends PreparedRequest object. Returns Response object.",
          "",
          "    :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.",
          "    :param stream: (optional) Whether to stream the request content.",
          "    :param timeout: (optional) How long to wait for the server to send",
          "        data before giving up, as a float, or a :ref:`(connect timeout,",
          "        read timeout) <timeouts>` tuple.",
          "    :type timeout: float or tuple",
          "    :param verify: (optional) Either a boolean, in which case it controls whether we verify",
          "        the server's TLS certificate, or a string, in which case it must be a path",
          "        to a CA bundle to use",
          "    :param cert: (optional) Any user-provided SSL certificate to be trusted.",
          "    :param proxies: (optional) The proxies dictionary to apply to the request.",
          "    \"\"\"",
          "    raise NotImplementedError"
        ]
      },
      {
        "id": 8,
        "dependency_name": "RequestHooksMixin.register_hook",
        "dependency_module": "requests.models",
        "dependency_file": "requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "requests/src/requests/models.py",
        "dependency_function_def": [
          "def register_hook(self, event, hook):",
          "    \"\"\"Properly register a hook.\"\"\"",
          "",
          "    if event not in self.hooks:",
          "        raise ValueError(f'Unsupported event specified, with event name \"{event}\"')",
          "",
          "    if isinstance(hook, Callable):",
          "        self.hooks[event].append(hook)",
          "    elif hasattr(hook, \"__iter__\"):",
          "        self.hooks[event].extend(h for h in hook if isinstance(h, Callable))"
        ]
      },
      {
        "id": 9,
        "dependency_name": "PreparedRequest.prepare_body (tell position)",
        "dependency_module": "requests.models",
        "dependency_file": "requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "requests/src/requests/models.py",
        "dependency_function_def": [
          "def prepare_body(self, data, files, json=None):",
          "    \"\"\"Prepares the given HTTP body data.\"\"\"",
          "",
          "    # Check if file, fo, generator, iterator.",
          "    # If not, run through normal process.",
          "",
          "    # Nottin' on you.",
          "    body = None",
          "    content_type = None",
          "",
          "    if not data and json is not None:",
          "        # urllib3 requires a bytes-like body. Python 2's json.dumps",
          "        # provides this natively, but Python 3 gives a Unicode string.",
          "        content_type = \"application/json\"",
          "",
          "        try:",
          "            body = complexjson.dumps(json, allow_nan=False)",
          "        except ValueError as ve:",
          "            raise InvalidJSONError(ve, request=self)",
          "",
          "        if not isinstance(body, bytes):",
          "            body = body.encode(\"utf-8\")",
          "",
          "    is_stream = all(",
          "        [",
          "            hasattr(data, \"__iter__\"),",
          "            not isinstance(data, (basestring, list, tuple, Mapping)),",
          "        ]",
          "    )",
          "",
          "    if is_stream:",
          "        try:",
          "            length = super_len(data)",
          "        except (TypeError, AttributeError, UnsupportedOperation):",
          "            length = None",
          "",
          "        body = data",
          "",
          "        if getattr(body, \"tell\", None) is not None:",
          "            # Record the current file position before reading.",
          "            # This will allow us to rewind a file in the event",
          "            # of a redirect.",
          "            try:",
          "                self._body_position = body.tell()",
          "            except OSError:",
          "                # This differentiates from None, allowing us to catch",
          "                # a failed `tell()` later when trying to rewind the body",
          "                self._body_position = object()",
          "",
          "        if files:",
          "            raise NotImplementedError(",
          "                \"Streamed bodies and files are mutually exclusive.\"",
          "            )",
          "",
          "        if length:",
          "            self.headers[\"Content-Length\"] = builtin_str(length)",
          "        else:",
          "            self.headers[\"Transfer-Encoding\"] = \"chunked\"",
          "    else:",
          "        # Multi-part file uploads.",
          "        if files:",
          "            (body, content_type) = self._encode_files(files, data)",
          "        else:",
          "            if data:",
          "                body = self._encode_params(data)",
          "                if isinstance(data, basestring) or hasattr(data, \"read\"):",
          "                    content_type = None",
          "                else:",
          "                    content_type = \"application/x-www-form-urlencoded\"",
          "",
          "        self.prepare_content_length(body)",
          "",
          "        # Add content-type if it wasn't explicitly provided.",
          "        if content_type and (\"content-type\" not in self.headers):",
          "            self.headers[\"Content-Type\"] = content_type",
          "",
          "    self.body = body"
        ]
      }
    ],
    "function_def": [
      "class HTTPDigestAuth(AuthBase):",
      "    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"",
      "",
      "    def __init__(self, username, password):",
      "        self.username = username",
      "        self.password = password",
      "        # Keep state in per-thread local storage",
      "        self._thread_local = threading.local()",
      "",
      "    def init_per_thread_state(self):",
      "        # Ensure state is initialized just once per-thread",
      "        if not hasattr(self._thread_local, \"init\"):",
      "            self._thread_local.init = True",
      "            self._thread_local.last_nonce = \"\"",
      "            self._thread_local.nonce_count = 0",
      "            self._thread_local.chal = {}",
      "            self._thread_local.pos = None",
      "            self._thread_local.num_401_calls = None",
      "",
      "    def build_digest_header(self, method, url):",
      "        \"\"\"",
      "        :rtype: str",
      "        \"\"\"",
      "",
      "        realm = self._thread_local.chal[\"realm\"]",
      "        nonce = self._thread_local.chal[\"nonce\"]",
      "        qop = self._thread_local.chal.get(\"qop\")",
      "        algorithm = self._thread_local.chal.get(\"algorithm\")",
      "        opaque = self._thread_local.chal.get(\"opaque\")",
      "        hash_utf8 = None",
      "",
      "        if algorithm is None:",
      "            _algorithm = \"MD5\"",
      "        else:",
      "            _algorithm = algorithm.upper()",
      "        if _algorithm == \"MD5\" or _algorithm == \"MD5-SESS\":",
      "            def md5_utf8(x):",
      "                if isinstance(x, str):",
      "                    x = x.encode(\"utf-8\")",
      "                return hashlib.md5(x).hexdigest()",
      "            hash_utf8 = md5_utf8",
      "        elif _algorithm == \"SHA\":",
      "            def sha_utf8(x):",
      "                if isinstance(x, str):",
      "                    x = x.encode(\"utf-8\")",
      "                return hashlib.sha1(x).hexdigest()",
      "            hash_utf8 = sha_utf8",
      "        elif _algorithm == \"SHA-256\":",
      "            def sha256_utf8(x):",
      "                if isinstance(x, str):",
      "                    x = x.encode(\"utf-8\")",
      "                return hashlib.sha256(x).hexdigest()",
      "            hash_utf8 = sha256_utf8",
      "        elif _algorithm == \"SHA-512\":",
      "            def sha512_utf8(x):",
      "                if isinstance(x, str):",
      "                    x = x.encode(\"utf-8\")",
      "                return hashlib.sha512(x).hexdigest()",
      "            hash_utf8 = sha512_utf8",
      "",
      "        KD = lambda s, d: hash_utf8(f\"{s}:{d}\")",
      "",
      "        if hash_utf8 is None:",
      "            return None",
      "",
      "        entdig = None",
      "        p_parsed = urlparse(url)",
      "        path = p_parsed.path or \"/\"",
      "        if p_parsed.query:",
      "            path += f\"?{p_parsed.query}\"",
      "",
      "        A1 = f\"{self.username}:{realm}:{self.password}\"",
      "        A2 = f\"{method}:{path}\"",
      "",
      "        HA1 = hash_utf8(A1)",
      "        HA2 = hash_utf8(A2)",
      "",
      "        if nonce == self._thread_local.last_nonce:",
      "            self._thread_local.nonce_count += 1",
      "        else:",
      "            self._thread_local.nonce_count = 1",
      "        ncvalue = f\"{self._thread_local.nonce_count:08x}\"",
      "        s = str(self._thread_local.nonce_count).encode(\"utf-8\")",
      "        s += nonce.encode(\"utf-8\")",
      "        s += time.ctime().encode(\"utf-8\")",
      "        s += os.urandom(8)",
      "",
      "        cnonce = hashlib.sha1(s).hexdigest()[:16]",
      "        if _algorithm == \"MD5-SESS\":",
      "            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")",
      "",
      "        if not qop:",
      "            respdig = KD(HA1, f\"{nonce}:{HA2}\")",
      "        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):",
      "            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"",
      "            respdig = KD(HA1, noncebit)",
      "        else:",
      "            return None",
      "",
      "        self._thread_local.last_nonce = nonce",
      "",
      "        base = (",
      "            f'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", '",
      "            f'uri=\"{path}\", response=\"{respdig}\"'",
      "        )",
      "        if opaque:",
      "            base += f', opaque=\"{opaque}\"'",
      "        if algorithm:",
      "            base += f', algorithm=\"{algorithm}\"'",
      "        if entdig:",
      "            base += f', digest=\"{entdig}\"'",
      "        if qop:",
      "            base += f', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"'",
      "",
      "        return f\"Digest {base}\"",
      "",
      "    def handle_redirect(self, r, **kwargs):",
      "        \"\"\"Reset num_401_calls counter on redirects.\"\"\"",
      "        if r.is_redirect:",
      "            self._thread_local.num_401_calls = 1",
      "",
      "    def handle_401(self, r, **kwargs):",
      "        \"\"\"Take the given response and tries digest-auth, if needed.\"\"\"",
      "        if not 400 <= r.status_code < 500:",
      "            self._thread_local.num_401_calls = 1",
      "            return r",
      "",
      "        if self._thread_local.pos is not None:",
      "            r.request.body.seek(self._thread_local.pos)",
      "        s_auth = r.headers.get(\"www-authenticate\", \"\")",
      "",
      "        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:",
      "            self._thread_local.num_401_calls += 1",
      "            pat = re.compile(r\"digest \", flags=re.IGNORECASE)",
      "            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))",
      "",
      "            r.content",
      "            r.close()",
      "            prep = r.request.copy()",
      "            extract_cookies_to_jar(prep._cookies, r.request, r.raw)",
      "            prep.prepare_cookies(prep._cookies)",
      "",
      "            prep.headers[\"Authorization\"] = self.build_digest_header(prep.method, prep.url)",
      "            _r = r.connection.send(prep, **kwargs)",
      "            _r.history.append(r)",
      "            _r.request = prep",
      "",
      "            return _r",
      "",
      "        self._thread_local.num_401_calls = 1",
      "        return r",
      "",
      "    def __call__(self, r):",
      "        self.init_per_thread_state()",
      "        if self._thread_local.last_nonce:",
      "            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)",
      "        try:",
      "            self._thread_local.pos = r.body.tell()",
      "        except AttributeError:",
      "            self._thread_local.pos = None",
      "        r.register_hook(\"response\", self.handle_401)",
      "        r.register_hook(\"response\", self.handle_redirect)",
      "        self._thread_local.num_401_calls = 1",
      "",
      "        return r"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_DIGEST_HTTP_200_OK_GET",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGEST_HTTP_200_OK_GET",
        "test_code": [
          "def test_DIGEST_HTTP_200_OK_GET(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")",
          "",
          "        r = requests.get(url, auth=auth)",
          "        assert r.status_code == 200",
          "",
          "        r = requests.get(url)",
          "        assert r.status_code == 401",
          "",
          "        s = requests.session()",
          "        s.auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        r = s.get(url)",
          "        assert r.status_code == 200"
        ]
      },
      {
        "id": 2,
        "test_name": "test_DIGEST_AUTH_RETURNS_COOKIE",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGEST_AUTH_RETURNS_COOKIE",
        "test_code": [
          "def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)",
          "        auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        r = requests.get(url)",
          "        assert r.cookies[\"fake\"] == \"fake_value\"",
          "",
          "        r = requests.get(url, auth=auth)",
          "        assert r.status_code == 200"
        ]
      },
      {
        "id": 3,
        "test_name": "test_DIGEST_AUTH_SETS_SESSION_COOKIES",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGEST_AUTH_SETS_SESSION_COOKIES",
        "test_code": [
          "def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)",
          "        auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        s = requests.Session()",
          "        s.get(url, auth=auth)",
          "        assert s.cookies[\"fake\"] == \"fake_value\""
        ]
      },
      {
        "id": 4,
        "test_name": "test_DIGEST_STREAM",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGEST_STREAM",
        "test_code": [
          "def test_DIGEST_STREAM(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)",
          "",
          "        r = requests.get(url, auth=auth, stream=True)",
          "        assert r.raw.read() != b\"\"",
          "",
          "        r = requests.get(url, auth=auth, stream=False)",
          "        assert r.raw.read() == b\"\""
        ]
      },
      {
        "id": 5,
        "test_name": "test_DIGESTAUTH_WRONG_HTTP_401_GET",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGESTAUTH_WRONG_HTTP_401_GET",
        "test_code": [
          "def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        auth = HTTPDigestAuth(\"user\", \"wrongpass\")",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)",
          "",
          "        r = requests.get(url, auth=auth)",
          "        assert r.status_code == 401",
          "",
          "        r = requests.get(url)",
          "        assert r.status_code == 401",
          "",
          "        s = requests.session()",
          "        s.auth = auth",
          "        r = s.get(url)",
          "        assert r.status_code == 401"
        ]
      },
      {
        "id": 6,
        "test_name": "test_DIGESTAUTH_QUOTES_QOP_VALUE",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_DIGESTAUTH_QUOTES_QOP_VALUE",
        "test_code": [
          "def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):",
          "    for authtype in self.digest_auth_algo:",
          "        auth = HTTPDigestAuth(\"user\", \"pass\")",
          "        url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)",
          "",
          "        r = requests.get(url, auth=auth)",
          "        assert '\"auth\"' in r.request.headers[\"Authorization\"]"
        ]
      }
    ],
    "fixtures": [
      "httpbin (used by existing integration tests to emit WWW-Authenticate challenges)",
      "threading (class uses thread-local state)",
      "pytest (parametrize / fixtures)"
    ],
    "description": "Implements RFC-style HTTP Digest Authentication: builds digest Authorization headers (build_digest_header), handles 401 flows (handle_401), manages per-thread state (init_per_thread_state), and registers response hooks. Useful security-relevant behaviors: header construction, nonce/cnonce handling, body rewind, and redirect/auth stripping.",
    "security_focus": [
      "credential_handling",
      "authorization_header_leakage",
      "redirect_safety",
      "body_rewind_and_leakage",
      "parsing_of_www_authenticate"
    ],
    "setup_notes": {
      "note": "Integration tests rely on the httpbin fixture. For single-function unit examples, populate an HTTPDigestAuth instance's _thread_local.chal with a minimal challenge (realm, nonce, qop, algorithm) and call build_digest_header(method, url). When sending this entry to an LLM, instruct it to produce self-contained unit tests that either mock the httpbin flow or directly call build_digest_header after setting thread-local state.",
      "recommendation": "Prefer supplying one small unit test targeting build_digest_header (pre-populate chal and nonce state) and one integration-style example that uses httpbin but instruct the LLM to mock network."
    }
  },
  {
    "name": "unquote_header_value",
    "module": "requests.utils",
    "file": "requests/src/requests/utils.py",
    "qualname": "requests.utils.unquote_header_value",
    "imports": [
      "import codecs",
      "import contextlib",
      "import io",
      "import os",
      "import re",
      "import socket",
      "import struct",
      "import sys",
      "import tempfile",
      "import warnings",
      "import zipfile",
      "from collections import OrderedDict",
      "",
      "from urllib3.util import make_headers, parse_url",
      "",
      "from . import certs",
      "from .__version__ import __version__",
      "",
      "# to_native_string is unused here, but imported here for backwards compatibility",
      "from ._internal_utils import (  # noqa: F401",
      "    _HEADER_VALIDATORS_BYTE,",
      "    _HEADER_VALIDATORS_STR,",
      "    HEADER_VALIDATORS,",
      "    to_native_string,",
      ")",
      "from .compat import (",
      "    Mapping,",
      "    basestring,",
      "    bytes,",
      "    getproxies,",
      "    getproxies_environment,",
      "    integer_types,",
      "    is_urllib3_1,",
      ")",
      "from .compat import parse_http_list as _parse_list_header",
      "from .compat import (",
      "    proxy_bypass,",
      "    proxy_bypass_environment,",
      "    quote,",
      "    str,",
      "    unquote,",
      "    urlparse,",
      "    urlunparse,",
      ")",
      "from .cookies import cookiejar_from_dict",
      "from .exceptions import (",
      "    FileModeWarning,",
      "    InvalidHeader,",
      "    InvalidURL,",
      "    UnrewindableBodyError,",
      ")",
      "from .structures import CaseInsensitiveDict",
      "",
      "NETRC_FILES = (\".netrc\", \"_netrc\")",
      "",
      "DEFAULT_CA_BUNDLE_PATH = certs.where()",
      "",
      "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}",
      "",
      "# Ensure that ', ' is used to preserve previous delimiter behavior.",
      "DEFAULT_ACCEPT_ENCODING = \", \".join(",
      "    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])",
      ")"
    ],
    "dependencies": [
      {
        "dependency_function_def": "No dependencies for this function were needed"
      }
    ],
    "function_def": [
      "def unquote_header_value(value, is_filename=False):",
      "    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).",
      "    This does not use the real unquoting but what browsers are actually",
      "    using for quoting.",
      "",
      "    :param value: the header value to unquote.",
      "    :rtype: str",
      "    \"\"\"",
      "    if value and value[0] == value[-1] == '\"':",
      "        # this is not the real unquoting, but fixing this so that the",
      "        # RFC is met will result in bugs with internet explorer and",
      "        # probably some other browsers as well.  IE for example is",
      "        # uploading files with \"C:\\\\foo\\\\bar.txt\" as filename",
      "        value = value[1:-1]",
      "",
      "        # if this is a filename and the starting characters look like",
      "        # a UNC path, then just return the value without quotes.  Using the",
      "        # replace sequence below on a UNC path has the effect of turning",
      "        # the leading double slash into a single slash and then",
      "        # _fix_ie_filename() doesn't work correctly.  See #458.",
      "        if not is_filename or value[:2] != \"\\\\\\\\\":",
      "            return value.replace('\\\\\\\\', '\\\\').replace('\\\"', '\"')",
      "    return value"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_valid",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::TestUnquoteHeaderValue::test_valid",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"value, expected\",",
          "    (",
          "        (None, None),",
          "        (\"Test\", \"Test\"),",
          "        ('\"Test\"', \"Test\"),",
          "        ('\"Test\\\\\\\\\"', \"Test\\\\\"),",
          "        ('\"\\\\\\\\Comp\\\\Res\"', \"\\\\Comp\\\\Res\"),",
          "    ),",
          ")",
          "def test_valid(value, expected):",
          "    assert unquote_header_value(value) == expected"
        ]
      },
      {
        "id": 2,
        "test_name": "test_is_filename",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::TestUnquoteHeaderValue::test_is_filename",
        "test_code": [
          "def test_is_filename():",
          "    assert unquote_header_value('\"\\\\\\\\Comp\\\\Res\"', True) == \"\\\\\\\\Comp\\\\Res\""
        ]
      }
    ],
    "fixtures": [],
    "description": "Remove quotes from header values and unescape backslash sequences in a browser-compatible way. If is_filename is True and the value looks like a UNC path (starts with \\\\\"\\\\\\\\), return the raw value without applying the backslash replacements.",
    "security_focus": [
      "output_sanitization",
      "string_unquoting_edge_cases",
      "avoid_injection_via_headers"
    ],
    "setup_notes": {
      "note": "This is a pure unit-level test (no network). Include the parametrized examples so an LLM sees cases with None, plain strings, quoted strings, and escaped backslashes/UNC paths.",
      "recommendation": "When generating runnable tests from this example, ensure proper escaping is preserved in test source (Python string literals)."
    }
  },
  {
    "name": "_parse_content_type_header",
    "module": "requests.utils",
    "file": "requests/src/requests/utils.py",
    "qualname": "requests.utils._parse_content_type_header",
    "imports": [
      "import codecs",
      "import contextlib",
      "import io",
      "import os",
      "import re",
      "import socket",
      "import struct",
      "import sys",
      "import tempfile",
      "import warnings",
      "import zipfile",
      "from collections import OrderedDict",
      "",
      "from urllib3.util import make_headers, parse_url",
      "",
      "from . import certs",
      "from .__version__ import __version__",
      "",
      "# to_native_string is unused here, but imported here for backwards compatibility",
      "from ._internal_utils import (  # noqa: F401",
      "    _HEADER_VALIDATORS_BYTE,",
      "    _HEADER_VALIDATORS_STR,",
      "    HEADER_VALIDATORS,",
      "    to_native_string,",
      ")",
      "from .compat import (",
      "    Mapping,",
      "    basestring,",
      "    bytes,",
      "    getproxies,",
      "    getproxies_environment,",
      "    integer_types,",
      "    is_urllib3_1,",
      ")",
      "from .compat import parse_http_list as _parse_list_header",
      "from .compat import (",
      "    proxy_bypass,",
      "    proxy_bypass_environment,",
      "    quote,",
      "    str,",
      "    unquote,",
      "    urlparse,",
      "    urlunparse,",
      ")",
      "from .cookies import cookiejar_from_dict",
      "from .exceptions import (",
      "    FileModeWarning,",
      "    InvalidHeader,",
      "    InvalidURL,",
      "    UnrewindableBodyError,",
      ")",
      "from .structures import CaseInsensitiveDict",
      "",
      "NETRC_FILES = (\".netrc\", \"_netrc\")",
      "",
      "DEFAULT_CA_BUNDLE_PATH = certs.where()",
      "",
      "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}",
      "",
      "# Ensure that ', ' is used to preserve previous delimiter behavior.",
      "DEFAULT_ACCEPT_ENCODING = \", \".join(",
      "    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])",
      ")"
    ],
    "dependencies": [
      {
        "dependency_function_def": "No dependencies for this function were needed"
      }
    ],
    "function_def": [
      "def _parse_content_type_header(header):",
      "    \"\"\"Returns content type and parameters from given header",
      "",
      "    :param header: string",
      "    :return: tuple containing content type and dictionary of",
      "         parameters",
      "    \"\"\"",
      "    tokens = header.split(\";\")",
      "    content_type, params = tokens[0].strip(), tokens[1:]",
      "    params_dict = {}",
      "    items_to_strip = \"\\\"' \"",
      "",
      "    for param in params:",
      "        param = param.strip()",
      "        if param:",
      "            key, value = param, True",
      "            index_of_equals = param.find(\"=\")",
      "            if index_of_equals != -1:",
      "                key = param[:index_of_equals].strip(items_to_strip)",
      "                value = param[index_of_equals + 1 :].strip(items_to_strip)",
      "            params_dict[key.lower()] = value",
      "    return content_type, params_dict"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test__parse_content_type_header",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::test__parse_content_type_header",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"value, expected\",",
          "    (",
          "        (\"application/xml\", (\"application/xml\", {})),",
          "        (",
          "            \"application/json ; charset=utf-8\",",
          "            (\"application/json\", {\"charset\": \"utf-8\"}),",
          "        ),",
          "        (",
          "            \"application/json ; Charset=utf-8\",",
          "            (\"application/json\", {\"charset\": \"utf-8\"}),",
          "        ),",
          "        (\"text/plain\", (\"text/plain\", {})),",
          "        (",
          "            \"multipart/form-data; boundary = something ; boundary2='something_else' ; no_equals \",",
          "            (",
          "                \"multipart/form-data\",",
          "                {",
          "                    \"boundary\": \"something\",",
          "                    \"boundary2\": \"something_else\",",
          "                    \"no_equals\": True,",
          "                },",
          "            ),",
          "        ),",
          "        (",
          "            'multipart/form-data; boundary = something ; boundary2=\"something_else\" ; no_equals ',",
          "            (",
          "                \"multipart/form-data\",",
          "                {",
          "                    \"boundary\": \"something\",",
          "                    \"boundary2\": \"something_else\",",
          "                    \"no_equals\": True,",
          "                },",
          "            ),",
          "        ),",
          "        (",
          "            \"multipart/form-data; boundary = something ; 'boundary2=something_else' ; no_equals \",",
          "            (",
          "                \"multipart/form-data\",",
          "                {",
          "                    \"boundary\": \"something\",",
          "                    \"boundary2\": \"something_else\",",
          "                    \"no_equals\": True,",
          "                },",
          "            ),",
          "        ),",
          "        (",
          "            'multipart/form-data; boundary = something ; \"boundary2=something_else\" ; no_equals ',",
          "            (",
          "                \"multipart/form-data\",",
          "                {",
          "                    \"boundary\": \"something\",",
          "                    \"boundary2\": \"something_else\",",
          "                    \"no_equals\": True,",
          "                },",
          "            ),",
          "        ),",
          "        (\"application/json ; ; \", (\"application/json\", {})),",
          "    ),",
          ")",
          "def test__parse_content_type_header(value, expected):",
          "    assert _parse_content_type_header(value) == expected"
        ]
      }
    ],
    "fixtures": [],
    "description": "Parse a Content-Type header into (media_type, params_dict). Handles extra whitespace, quoted params, and missing values.",
    "security_focus": [
      "header_parsing",
      "parameter_injection",
      "correct_handling_of_quotes"
    ],
    "setup_notes": {
      "note": "Pure unit tests; include parametrized examples to show varied quoting and spacing cases."
    }
  },
  {
    "name": "select_proxy",
    "module": "requests.utils",
    "file": "requests/src/requests/utils.py",
    "qualname": "requests.utils.select_proxy",
    "imports": [
      "import codecs",
      "import contextlib",
      "import io",
      "import os",
      "import re",
      "import socket",
      "import struct",
      "import sys",
      "import tempfile",
      "import warnings",
      "import zipfile",
      "from collections import OrderedDict",
      "",
      "from urllib3.util import make_headers, parse_url",
      "",
      "from . import certs",
      "from .__version__ import __version__",
      "",
      "# to_native_string is unused here, but imported here for backwards compatibility",
      "from ._internal_utils import (  # noqa: F401",
      "    _HEADER_VALIDATORS_BYTE,",
      "    _HEADER_VALIDATORS_STR,",
      "    HEADER_VALIDATORS,",
      "    to_native_string,",
      ")",
      "from .compat import (",
      "    Mapping,",
      "    basestring,",
      "    bytes,",
      "    getproxies,",
      "    getproxies_environment,",
      "    integer_types,",
      "    is_urllib3_1,",
      ")",
      "from .compat import parse_http_list as _parse_list_header",
      "from .compat import (",
      "    proxy_bypass,",
      "    proxy_bypass_environment,",
      "    quote,",
      "    str,",
      "    unquote,",
      "    urlparse,",
      "    urlunparse,",
      ")",
      "from .cookies import cookiejar_from_dict",
      "from .exceptions import (",
      "    FileModeWarning,",
      "    InvalidHeader,",
      "    InvalidURL,",
      "    UnrewindableBodyError,",
      ")",
      "from .structures import CaseInsensitiveDict",
      "",
      "NETRC_FILES = (\".netrc\", \"_netrc\")",
      "",
      "DEFAULT_CA_BUNDLE_PATH = certs.where()",
      "",
      "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}",
      "",
      "# Ensure that ', ' is used to preserve previous delimiter behavior.",
      "DEFAULT_ACCEPT_ENCODING = \", \".join(",
      "    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "urlparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlparse(url, scheme='', allow_fragments=True):",
          "    \"\"\"Parse a URL into 6 components:",
          "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
          "",
          "    The result is a named 6-tuple with fields corresponding to the",
          "    above. It is either a ParseResult or ParseResultBytes object,",
          "    depending on the type of the url parameter.",
          "",
          "    The username, password, hostname, and port sub-components of netloc",
          "    can also be accessed as attributes of the returned object.",
          "",
          "    The scheme argument provides the default value of the scheme",
          "    component when no scheme is found in url.",
          "",
          "    If allow_fragments is False, no attempt is made to separate the",
          "    fragment component from the previous component, which can be either",
          "    path or query.",
          "",
          "    Note that % escapes are not expanded.",
          "    \"\"\"",
          "    url, scheme, _coerce_result = _coerce_args(url, scheme)",
          "    splitresult = urlsplit(url, scheme, allow_fragments)",
          "    scheme, netloc, url, query, fragment = splitresult",
          "    if scheme in uses_params and ';' in url:",
          "        url, params = _splitparams(url)",
          "    else:",
          "        params = ''",
          "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
          "    return _coerce_result(result)"
        ]
      }
    ],
    "function_def": [
      "def select_proxy(url, proxies):",
      "    \"\"\"Select a proxy for the url, if applicable.",
      "",
      "    :param url: The url being for the request",
      "    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs",
      "    \"\"\"",
      "    proxies = proxies or {}",
      "    urlparts = urlparse(url)",
      "    if urlparts.hostname is None:",
      "        return proxies.get(urlparts.scheme, proxies.get(\"all\"))",
      "",
      "    proxy_keys = [",
      "        urlparts.scheme + \"://\" + urlparts.hostname,",
      "        urlparts.scheme,",
      "        \"all://\" + urlparts.hostname,",
      "        \"all\",",
      "    ]",
      "    proxy = None",
      "    for proxy_key in proxy_keys:",
      "        if proxy_key in proxies:",
      "            proxy = proxies[proxy_key]",
      "            break",
      "",
      "    return proxy"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_select_proxies",
        "test_file": "requests/tests/test_utils.py",
        "test_nodeid": "requests/tests/test_utils.py::test_select_proxies",
        "test_code": [
          "http_proxies = {",
          "    \"http\": \"http://http.proxy\",",
          "    \"http://some.host\": \"http://some.host.proxy\",",
          "}",
          "all_proxies = {",
          "    \"all\": \"socks5://http.proxy\",",
          "    \"all://some.host\": \"socks5://some.host.proxy\",",
          "}",
          "mixed_proxies = {",
          "    \"http\": \"http://http.proxy\",",
          "    \"http://some.host\": \"http://some.host.proxy\",",
          "    \"all\": \"socks5://http.proxy\",",
          "}",
          "",
          "@pytest.mark.parametrize(",
          "    \"url, expected, proxies\",",
          "    (",
          "        (\"hTTp://u:p@Some.Host/path\", \"http://some.host.proxy\", http_proxies),",
          "        (\"hTTp://u:p@Other.Host/path\", \"http://http.proxy\", http_proxies),",
          "        (\"hTTp:///path\", \"http://http.proxy\", http_proxies),",
          "        (\"hTTps://Other.Host\", None, http_proxies),",
          "        (\"file:///etc/motd\", None, http_proxies),",
          "        (\"hTTp://u:p@Some.Host/path\", \"socks5://some.host.proxy\", all_proxies),",
          "        (\"hTTp://u:p@Other.Host/path\", \"socks5://http.proxy\", all_proxies),",
          "        (\"hTTp:///path\", \"socks5://http.proxy\", all_proxies),",
          "        (\"hTTps://Other.Host\", \"socks5://http.proxy\", all_proxies),",
          "        (\"http://u:p@other.host/path\", \"http://http.proxy\", mixed_proxies),",
          "        (\"http://u:p@some.host/path\", \"http://some.host.proxy\", mixed_proxies),",
          "        (\"https://u:p@other.host/path\", \"socks5://http.proxy\", mixed_proxies),",
          "        (\"https://u:p@some.host/path\", \"socks5://http.proxy\", mixed_proxies),",
          "        (\"https://\", \"socks5://http.proxy\", mixed_proxies),",
          "        # XXX: unsure whether this is reasonable behavior",
          "        (\"file:///etc/motd\", \"socks5://http.proxy\", all_proxies),",
          "    ),",
          ")",
          "def test_select_proxies(url, expected, proxies):",
          "    assert select_proxy(url, proxies) == expected"
        ]
      }
    ],
    "fixtures": [],
    "description": "Return the most specific matching proxy from the provided proxies mapping for a given URL. Preference order: scheme://hostname, scheme, all://hostname, all. Returns None if no match and hostname is present; uses scheme/all fallback when hostname is missing.",
    "security_focus": [
      "proxy_selection_correctness",
      "avoid_proxy_auth_leakage"
    ],
    "setup_notes": {
      "note": "Unit test is self-contained; ensure test imports the local utils.select_proxy implementation (PYTHONPATH) so it doesn't pick an installed package."
    }
  },
  {
    "name": "should_strip_auth",
    "module": "requests.sessions",
    "file": "requests/src/requests/sessions.py",
    "qualname": "requests.sessions.SessionRedirectMixin.should_strip_auth",
    "imports": [
      "import os",
      "import sys",
      "import time",
      "from collections import OrderedDict",
      "from datetime import timedelta",
      "",
      "from ._internal_utils import to_native_string",
      "from .adapters import HTTPAdapter",
      "from .auth import _basic_auth_str",
      "from .compat import Mapping, cookielib, urljoin, urlparse",
      "from .cookies import (",
      "    RequestsCookieJar,",
      "    cookiejar_from_dict,",
      "    extract_cookies_to_jar,",
      "    merge_cookies,",
      ")",
      "from .exceptions import (",
      "    ChunkedEncodingError,",
      "    ContentDecodingError,",
      "    InvalidSchema,",
      "    TooManyRedirects,",
      ")",
      "from .hooks import default_hooks, dispatch_hook",
      "",
      "# formerly defined here, reexposed here for backward compatibility",
      "from .models import (  # noqa: F401",
      "    DEFAULT_REDIRECT_LIMIT,",
      "    REDIRECT_STATI,",
      "    PreparedRequest,",
      "    Request,",
      ")",
      "from .status_codes import codes",
      "from .structures import CaseInsensitiveDict",
      "from .utils import (  # noqa: F401",
      "    DEFAULT_PORTS,",
      "    default_headers,",
      "    get_auth_from_url,",
      "    get_environ_proxies,",
      "    get_netrc_auth,",
      "    requote_uri,",
      "    resolve_proxies,",
      "    rewind_body,",
      "    should_bypass_proxies,",
      "    to_key_val_list,",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "urlparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlparse(url, scheme='', allow_fragments=True):",
          "    \"\"\"Parse a URL into 6 components:",
          "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
          "",
          "    The result is a named 6-tuple with fields corresponding to the",
          "    above. It is either a ParseResult or ParseResultBytes object,",
          "    depending on the type of the url parameter.",
          "",
          "    The username, password, hostname, and port sub-components of netloc",
          "    can also be accessed as attributes of the returned object.",
          "",
          "    The scheme argument provides the default value of the scheme",
          "    component when no scheme is found in url.",
          "",
          "    If allow_fragments is False, no attempt is made to separate the",
          "    fragment component from the previous component, which can be either",
          "    path or query.",
          "",
          "    Note that % escapes are not expanded.",
          "    \"\"\"",
          "    url, scheme, _coerce_result = _coerce_args(url, scheme)",
          "    splitresult = urlsplit(url, scheme, allow_fragments)",
          "    scheme, netloc, url, query, fragment = splitresult",
          "    if scheme in uses_params and ';' in url:",
          "        url, params = _splitparams(url)",
          "    else:",
          "        params = ''",
          "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
          "    return _coerce_result(result)"
        ]
      },
      {
        "id": 2,
        "dependency_name": "DEFAULT_PORTS",
        "dependency_module": "requests.utils",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/utils.py",
        "imported_via_module": "requests.utils",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}"
        ]
      }
    ],
    "function_def": [
      "def should_strip_auth(self, old_url, new_url):",
      "    \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"",
      "    old_parsed = urlparse(old_url)",
      "    new_parsed = urlparse(new_url)",
      "    if old_parsed.hostname != new_parsed.hostname:",
      "        return True",
      "    # Special case: allow http -> https redirect when using the standard",
      "    # ports. This isn't specified by RFC 7235, but is kept to avoid",
      "    # breaking backwards compatibility with older versions of requests",
      "    # that allowed any redirects on the same host.",
      "    if (",
      "        old_parsed.scheme == \"http\"",
      "        and old_parsed.port in (80, None)",
      "        and new_parsed.scheme == \"https\"",
      "        and new_parsed.port in (443, None)",
      "    ):",
      "        return False",
      "",
      "    # Handle default port usage corresponding to scheme.",
      "    changed_port = old_parsed.port != new_parsed.port",
      "    changed_scheme = old_parsed.scheme != new_parsed.scheme",
      "    default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)",
      "    if (",
      "        not changed_scheme",
      "        and old_parsed.port in default_port",
      "        and new_parsed.port in default_port",
      "    ):",
      "        return False",
      "",
      "    # Standard case: root URI must match",
      "    return changed_port or changed_scheme"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_should_strip_auth_host_change",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_should_strip_auth_host_change",
        "test_code": [
          "def test_should_strip_auth_host_change(self):",
          "    s = requests.Session()",
          "    assert s.should_strip_auth(",
          "        \"http://example.com/foo\", \"http://another.example.com/\"",
          "    )"
        ]
      },
      {
        "id": 2,
        "test_name": "test_should_strip_auth_http_downgrade",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_should_strip_auth_http_downgrade",
        "test_code": [
          "def test_should_strip_auth_http_downgrade(self):",
          "    s = requests.Session()",
          "    assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")"
        ]
      },
      {
        "id": 3,
        "test_name": "test_should_strip_auth_https_upgrade",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_should_strip_auth_https_upgrade",
        "test_code": [
          "def test_should_strip_auth_https_upgrade(self):",
          "    s = requests.Session()",
          "    assert not s.should_strip_auth(",
          "        \"http://example.com/foo\", \"https://example.com/bar\"",
          "    )",
          "    assert not s.should_strip_auth(",
          "        \"http://example.com:80/foo\", \"https://example.com/bar\"",
          "    )",
          "    assert not s.should_strip_auth(",
          "        \"http://example.com/foo\", \"https://example.com:443/bar\"",
          "    )",
          "    # Non-standard ports should trigger stripping",
          "    assert s.should_strip_auth(",
          "        \"http://example.com:8080/foo\", \"https://example.com/bar\"",
          "    )",
          "    assert s.should_strip_auth(",
          "        \"http://example.com/foo\", \"https://example.com:8443/bar\"",
          "    )"
        ]
      },
      {
        "id": 4,
        "test_name": "test_should_strip_auth_port_change",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_should_strip_auth_port_change",
        "test_code": [
          "def test_should_strip_auth_port_change(self):",
          "    s = requests.Session()",
          "    assert s.should_strip_auth(",
          "        \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"",
          "    )"
        ]
      },
      {
        "id": 5,
        "test_name": "test_should_strip_auth_default_port",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_should_strip_auth_default_port",
        "test_code": [
          "@pytest.mark.parametrize(",
          "    \"old_uri, new_uri\",",
          "    (",
          "        (\"https://example.com:443/foo\", \"https://example.com/bar\"),",
          "        (\"http://example.com:80/foo\", \"http://example.com/bar\"),",
          "        (\"https://example.com/foo\", \"https://example.com:443/bar\"),",
          "        (\"http://example.com/foo\", \"http://example.com:80/bar\"),",
          "    ),",
          ")",
          "def test_should_strip_auth_default_port(self, old_uri, new_uri):",
          "    s = requests.Session()",
          "    assert not s.should_strip_auth(old_uri, new_uri)"
        ]
      }
    ],
    "fixtures": [
      "requests.Session() (used to call the mixin method in tests)",
      "pytest (for parametrize)"
    ],
    "description": "Decide whether Authorization header should be stripped when following redirects. Covers hostname changes, http->https/https->http port/scheme rules, and default-port equivalence handling.",
    "security_focus": [
      "authorization_header_leakage",
      "redirect_safety",
      "credential_exposure_on_host_change"
    ],
    "setup_notes": {
      "note": "Mostly E2E. Unit tests call the session.should_strip_auth from a Session instance. Ensure imports resolve to the local sessions module when running tests (PYTHONPATH). Parametrized test preserved as-is."
    }
  },
  {
    "name": "rebuild_auth",
    "module": "requests.sessions",
    "file": "requests/src/requests/sessions.py",
    "qualname": "requests.sessions.SessionRedirectMixin.rebuild_auth",
    "imports": [
      "import os",
      "import sys",
      "import time",
      "from collections import OrderedDict",
      "from datetime import timedelta",
      "",
      "from ._internal_utils import to_native_string",
      "from .adapters import HTTPAdapter",
      "from .auth import _basic_auth_str",
      "from .compat import Mapping, cookielib, urljoin, urlparse",
      "from .cookies import (",
      "    RequestsCookieJar,",
      "    cookiejar_from_dict,",
      "    extract_cookies_to_jar,",
      "    merge_cookies,",
      ")",
      "from .exceptions import (",
      "    ChunkedEncodingError,",
      "    ContentDecodingError,",
      "    InvalidSchema,",
      "    TooManyRedirects,",
      ")",
      "from .hooks import default_hooks, dispatch_hook",
      "",
      "# formerly defined here, reexposed here for backward compatibility",
      "from .models import (  # noqa: F401",
      "    DEFAULT_REDIRECT_LIMIT,",
      "    REDIRECT_STATI,",
      "    PreparedRequest,",
      "    Request,",
      ")",
      "from .status_codes import codes",
      "from .structures import CaseInsensitiveDict",
      "from .utils import (  # noqa: F401",
      "    DEFAULT_PORTS,",
      "    default_headers,",
      "    get_auth_from_url,",
      "    get_environ_proxies,",
      "    get_netrc_auth,",
      "    requote_uri,",
      "    resolve_proxies,",
      "    rewind_body,",
      "    should_bypass_proxies,",
      "    to_key_val_list,",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "get_netrc_auth",
        "dependency_module": "requests.utils",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/utils.py",
        "imported_via_module": "requests.utils",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def get_netrc_auth(url, raise_errors=False):",
          "    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"",
          "",
          "    netrc_file = os.environ.get(\"NETRC\")",
          "    if netrc_file is not None:",
          "        netrc_locations = (netrc_file,)",
          "    else:",
          "        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)",
          "",
          "    try:",
          "        from netrc import NetrcParseError, netrc",
          "",
          "        netrc_path = None",
          "",
          "        for f in netrc_locations:",
          "            loc = os.path.expanduser(f)",
          "            if os.path.exists(loc):",
          "                ",
          "",
          "        # Abort early if there isn't one.",
          "        if netrc_path is None:",
          "            return",
          "",
          "        ri = urlparse(url)",
          "        host = ri.hostname",
          "",
          "        try:",
          "            _netrc = netrc(netrc_path).authenticators(host)",
          "            if _netrc:",
          "                ",
          "        except (NetrcParseError, OSError):",
          "            # If there was a parsing error or a permissions issue reading the file,",
          "            # we'll just skip netrc auth unless explicitly asked to raise errors.",
          "            if raise_errors:",
          "                ",
          "",
          "    # App Engine hackiness.",
          "    except (ImportError, AttributeError):",
          "        pass"
        ]
      },
      {
        "id": 2,
        "dependency_name": "PreparedRequest.prepare_auth",
        "dependency_module": "requests.models",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def prepare_auth(self, auth, url=\"\"):",
          "    \"\"\"Prepares the given HTTP auth data.\"\"\"",
          "",
          "    # If no Auth is explicitly provided, extract it from the URL first.",
          "    if auth is None:",
          "        url_auth = get_auth_from_url(self.url)",
          "        auth = url_auth if any(url_auth) else None",
          "",
          "    if auth:",
          "        if isinstance(auth, tuple) and len(auth) == 2:",
          "            # special-case basic HTTP auth",
          "            auth = HTTPBasicAuth(*auth)",
          "",
          "        # Allow auth to make its changes.",
          "        r = auth(self)",
          "",
          "        # Update self to reflect the auth changes.",
          "        self.__dict__.update(r.__dict__)",
          "",
          "        # Recompute Content-Length",
          "        self.prepare_content_length(self.body)"
        ]
      }
    ],
    "function_def": [
      "def rebuild_auth(self, prepared_request, response):",
      "    \"\"\"When being redirected we may want to strip authentication from the",
      "    request to avoid leaking credentials. This method intelligently removes",
      "    and reapplies authentication where possible to avoid credential loss.",
      "    \"\"\"",
      "    headers = prepared_request.headers",
      "    url = prepared_request.url",
      "",
      "    if \"Authorization\" in headers and self.should_strip_auth(",
      "        response.request.url, url",
      "    ):",
      "        # If we get redirected to a new host, we should strip out any",
      "        # authentication headers.",
      "        del headers[\"Authorization\"]",
      "",
      "    # .netrc might have more auth for us on our new host.",
      "    new_auth = get_netrc_auth(url) if self.trust_env else None",
      "    if new_auth is not None:",
      "        prepared_request.prepare_auth(new_auth)"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_auth_is_stripped_on_http_downgrade",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_auth_is_stripped_on_http_downgrade",
        "test_code": [
          "def test_auth_is_stripped_on_http_downgrade(self, httpbin, httpbin_secure, httpbin_ca_bundle):",
          "    r = requests.get(",
          "        httpbin_secure(\"redirect-to\"),",
          "        params={\"url\": httpbin(\"get\")},",
          "        auth=(\"user\", \"pass\"),",
          "        verify=httpbin_ca_bundle,",
          "    )",
          "    assert r.history[0].request.headers[\"Authorization\"]",
          "    assert \"Authorization\" not in r.request.headers"
        ]
      },
      {
        "id": 2,
        "test_name": "test_auth_is_retained_for_redirect_on_host",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_auth_is_retained_for_redirect_on_host",
        "test_code": [
          "def test_auth_is_retained_for_redirect_on_host(self, httpbin):",
          "    r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))",
          "    h1 = r.history[0].request.headers[\"Authorization\"]",
          "    h2 = r.request.headers[\"Authorization\"]",
          "",
          "    assert h1 == h2"
        ]
      }
    ],
    "fixtures": [
      "httpbin (local http test server)",
      "httpbin_secure (TLS-enabled httpbin for redirect->http downgrade test)",
      "httpbin_ca_bundle (CA bundle for secure httpbin)"
    ],
    "description": "Handle Authorization header during redirects: strip Authorization when should_strip_auth indicates leakage (e.g., http downgrade or host change) and re-apply .netrc credentials when available via get_netrc_auth (if trust_env).",
    "security_focus": [
      "authorization_header_leakage",
      "redirect_safety",
      "credential_exposure_on_redirects",
      "netrc_credential_handling"
    ],
    "setup_notes": {
      "note": "These are integration tests that expect the httpbin fixtures. For unit-style tests, mock SessionRedirectMixin.should_strip_auth, requests.sessions.get_netrc_auth and supply a PreparedRequest/Response pair to call rebuild_auth directly."
    }
  },
  {
    "name": "resolve_redirects",
    "module": "requests.sessions",
    "file": "requests/src/requests/sessions.py",
    "qualname": "requests.sessions.SessionRedirectMixin.resolve_redirects",
    "imports": [
      "import os",
      "import sys",
      "import time",
      "from collections import OrderedDict",
      "from datetime import timedelta",
      "",
      "from ._internal_utils import to_native_string",
      "from .adapters import HTTPAdapter",
      "from .auth import _basic_auth_str",
      "from .compat import Mapping, cookielib, urljoin, urlparse",
      "from .cookies import (",
      "    RequestsCookieJar,",
      "    cookiejar_from_dict,",
      "    extract_cookies_to_jar,",
      "    merge_cookies,",
      ")",
      "from .exceptions import (",
      "    ChunkedEncodingError,",
      "    ContentDecodingError,",
      "    InvalidSchema,",
      "    TooManyRedirects,",
      ")",
      "from .hooks import default_hooks, dispatch_hook",
      "",
      "# formerly defined here, reexposed here for backward compatibility",
      "from .models import (  # noqa: F401",
      "    DEFAULT_REDIRECT_LIMIT,",
      "    REDIRECT_STATI,",
      "    PreparedRequest,",
      "    Request,",
      ")",
      "from .status_codes import codes",
      "from .structures import CaseInsensitiveDict",
      "from .utils import (  # noqa: F401",
      "    DEFAULT_PORTS,",
      "    default_headers,",
      "    get_auth_from_url,",
      "    get_environ_proxies,",
      "    get_netrc_auth,",
      "    requote_uri,",
      "    resolve_proxies,",
      "    rewind_body,",
      "    should_bypass_proxies,",
      "    to_key_val_list,",
      ")"
    ],
    "dependencies": [
      {
        "id": 1,
        "dependency_name": "urlparse",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urlparse(url, scheme='', allow_fragments=True):",
          "    \"\"\"Parse a URL into 6 components:",
          "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
          "",
          "    The result is a named 6-tuple with fields corresponding to the",
          "    above. It is either a ParseResult or ParseResultBytes object,",
          "    depending on the type of the url parameter.",
          "",
          "    The username, password, hostname, and port sub-components of netloc",
          "    can also be accessed as attributes of the returned object.",
          "",
          "    The scheme argument provides the default value of the scheme",
          "    component when no scheme is found in url.",
          "",
          "    If allow_fragments is False, no attempt is made to separate the",
          "    fragment component from the previous component, which can be either",
          "    path or query.",
          "",
          "    Note that % escapes are not expanded.",
          "    \"\"\"",
          "    url, scheme, _coerce_result = _coerce_args(url, scheme)",
          "    splitresult = urlsplit(url, scheme, allow_fragments)",
          "    scheme, netloc, url, query, fragment = splitresult",
          "    if scheme in uses_params and ';' in url:",
          "        url, params = _splitparams(url)",
          "    else:",
          "        params = ''",
          "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
          "    return _coerce_result(result)"
        ]
      },
      {
        "id": 2,
        "dependency_name": "urljoin",
        "dependency_module": "urllib.parse",
        "dependency_file": "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/parse.py",
        "imported_via_module": "requests.compat",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/compat.py",
        "dependency_function_def": [
          "def urljoin(base, url, allow_fragments=True):",
          "    \"\"\"Join a base URL and a possibly relative URL to form an absolute",
          "    interpretation of the latter.\"\"\"",
          "    if not base:",
          "        return url",
          "    if not url:",
          "        return base",
          "",
          "    base, url, _coerce_result = _coerce_args(base, url)",
          "    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\",
          "            urlparse(base, '', allow_fragments)",
          "    scheme, netloc, path, params, query, fragment = \\",
          "            urlparse(url, bscheme, allow_fragments)",
          "",
          "    if scheme != bscheme or scheme not in uses_relative:",
          "        return _coerce_result(url)",
          "    if scheme in uses_netloc:",
          "        if netloc:",
          "            return _coerce_result(urlunparse((scheme, netloc, path,",
          "                                              params, query, fragment)))",
          "        netloc = bnetloc",
          "",
          "    if not path and not params:",
          "        path = bpath",
          "        params = bparams",
          "        if not query:",
          "            query = bquery",
          "        return _coerce_result(urlunparse((scheme, netloc, path,",
          "                                          params, query, fragment)))",
          "",
          "    base_parts = bpath.split('/')",
          "    if base_parts[-1] != '':",
          "        # the last item is not a directory, so will not be taken into account",
          "        # in resolving the relative path",
          "        del base_parts[-1]",
          "",
          "    # for rfc3986, ignore all base path should the first character be root.",
          "    if path[:1] == '/':",
          "        segments = path.split('/')",
          "    else:",
          "        segments = base_parts + path.split('/')",
          "        # filter out elements that would cause redundant slashes on re-joining",
          "        # the resolved_path",
          "        segments[1:-1] = filter(None, segments[1:-1])",
          "",
          "    resolved_path = []",
          "",
          "    for seg in segments:",
          "        if seg == '..':",
          "            try:",
          "                resolved_path.pop()",
          "            except IndexError:",
          "                # ignore any .. segments that would otherwise cause an IndexError",
          "                # when popped from resolved_path if resolving for rfc3986",
          "                pass",
          "        elif seg == '.':",
          "            continue",
          "        else:",
          "            resolved_path.append(seg)",
          "",
          "    if segments[-1] in ('.', '..'):",
          "        # do some post-processing here. if the last segment was a relative dir,",
          "        # then we need to append the trailing '/'",
          "        resolved_path.append('')",
          "",
          "    return _coerce_result(urlunparse((scheme, netloc, '/'.join(",
          "        resolved_path) or '/', params, query, fragment)))"
        ]
      },
      {
        "id": 3,
        "dependency_name": "requote_uri",
        "dependency_module": "requests.utils",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/utils.py",
        "imported_via_module": "requests.utils",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def requote_uri(uri):",
          "    \"\"\"Re-quote the given URI.",
          "",
          "    This function passes the given URI through an unquote/quote cycle to",
          "    ensure that it is fully and consistently quoted.",
          "",
          "    :rtype: str",
          "    \"\"\"",
          "    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"",
          "    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"",
          "    try:",
          "        # Unquote only the unreserved characters",
          "        # Then quote only illegal characters (do not quote reserved,",
          "        # unreserved, or '%')",
          "        return quote(unquote_unreserved(uri), safe=safe_with_percent)",
          "    except InvalidURL:",
          "        # We couldn't unquote the given URI, so let's try quoting it, but",
          "        # there may be unquoted '%'s in the URI. We need to make sure they're",
          "        # properly quoted so they do not cause issues elsewhere.",
          "        return quote(uri, safe=safe_without_percent)"
        ]
      },
      {
        "id": 4,
        "dependency_name": "rewind_body",
        "dependency_module": "requests.utils",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/utils.py",
        "imported_via_module": "requests.utils",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def rewind_body(prepared_request):",
          "    \"\"\"Move file pointer back to its recorded starting position",
          "    so it can be read again on redirect.",
          "    \"\"\"",
          "    body_seek = getattr(prepared_request.body, \"seek\", None)",
          "    if body_seek is not None and isinstance(",
          "        prepared_request._body_position, integer_types",
          "    ):",
          "        try:",
          "            ",
          "        except OSError:",
          "            ",
          "    else:",
          "        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")"
        ]
      },
      {
        "id": 5,
        "dependency_name": "extract_cookies_to_jar",
        "dependency_module": "requests.cookies",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/cookies.py",
        "imported_via_module": "requests.cookies",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def extract_cookies_to_jar(jar, request, response):",
          "    \"\"\"Extract the cookies from the response into a CookieJar.",
          "",
          "    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)",
          "    :param request: our own requests.Request object",
          "    :param response: urllib3.HTTPResponse object",
          "    \"\"\"",
          "    if not (hasattr(response, \"_original_response\") and response._original_response):",
          "        return",
          "    # the _original_response field is the wrapped httplib.HTTPResponse object,",
          "    req = MockRequest(request)",
          "    # pull out the HTTPMessage with the headers and put it in the mock:",
          "    res = MockResponse(response._original_response.msg)",
          "    jar.extract_cookies(res, req)"
        ]
      },
      {
        "id": 6,
        "dependency_name": "merge_cookies",
        "dependency_module": "requests.cookies",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/cookies.py",
        "imported_via_module": "requests.cookies",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def merge_cookies(cookiejar, cookies):",
          "    \"\"\"Add cookies to cookiejar and returns a merged CookieJar.",
          "",
          "    :param cookiejar: CookieJar object to add the cookies to.",
          "    :param cookies: Dictionary or CookieJar object to be added.",
          "    :rtype: CookieJar",
          "    \"\"\"",
          "    if not isinstance(cookiejar, cookielib.CookieJar):",
          "        raise ValueError(\"You can only merge into CookieJar\")",
          "",
          "    if isinstance(cookies, dict):",
          "        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)",
          "    elif isinstance(cookies, cookielib.CookieJar):",
          "        try:",
          "            cookiejar.update(cookies)",
          "        except AttributeError:",
          "            for cookie_in_jar in cookies:",
          "                cookiejar.set_cookie(cookie_in_jar)",
          "",
          "    return cookiejar"
        ]
      },
      {
        "id": 7,
        "dependency_name": "PreparedRequest.copy",
        "dependency_module": "requests.models",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def copy(self):",
          "    p = PreparedRequest()",
          "    p.method = self.method",
          "    p.url = self.url",
          "    p.headers = self.headers.copy() if self.headers is not None else None",
          "    p._cookies = _copy_cookie_jar(self._cookies)",
          "    p.body = self.body",
          "    p.hooks = self.hooks",
          "    p._body_position = self._body_position",
          "    return p"
        ]
      },
      {
        "id": 8,
        "dependency_name": "PreparedRequest.prepare_cookies",
        "dependency_module": "requests.models",
        "dependency_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/models.py",
        "imported_via_module": "requests.models",
        "imported_via_file": "/Users/dilaynurlu/evaluatingLLM/requests/src/requests/sessions.py",
        "dependency_function_def": [
          "def prepare_cookies(self, cookies):",
          "    \"\"\"Prepares the given HTTP cookie data.",
          "",
          "    This function eventually generates a ``Cookie`` header from the",
          "    given cookies using cookielib. Due to cookielib's design, the header",
          "    will not be regenerated if it already exists, meaning this function",
          "    can only be called once for the life of the",
          "    :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls",
          "    to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"",
          "    header is removed beforehand.",
          "    \"\"\"",
          "    if isinstance(cookies, cookielib.CookieJar):",
          "        self._cookies = cookies",
          "    else:",
          "        self._cookies = cookiejar_from_dict(cookies)",
          "",
          "    cookie_header = get_cookie_header(self._cookies, self)",
          "    if cookie_header is not None:",
          "        self.headers[\"Cookie\"] = cookie_header"
        ]
      }
    ],
    "function_def": [
      "def resolve_redirects(self,",
      "        resp,",
      "        req,",
      "        stream=False,",
      "        timeout=None,",
      "        verify=True,",
      "        cert=None,",
      "        proxies=None,",
      "        yield_requests=False,",
      "        **adapter_kwargs,",
      "    ):",
      "    \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"",
      "",
      "    hist = []  # keep track of history",
      "",
      "    url = self.get_redirect_target(resp)",
      "    previous_fragment = urlparse(req.url).fragment",
      "    while url:",
      "        prepared_request = req.copy()",
      "",
      "        # Update history and keep track of redirects.",
      "        # resp.history must ignore the original request in this loop",
      "        hist.append(resp)",
      "        resp.history = hist[1:]",
      "",
      "        try:",
      "            resp.content  # Consume socket so it can be released",
      "        except (ChunkedEncodingError, ContentDecodingError, RuntimeError):",
      "            resp.raw.read(decode_content=False)",
      "",
      "        if len(resp.history) >= self.max_redirects:",
      "            raise TooManyRedirects(",
      "                f\"Exceeded {self.max_redirects} redirects.\", response=resp",
      "            )",
      "",
      "        # Release the connection back into the pool.",
      "        resp.close()",
      "",
      "        # Handle redirection without scheme (see: RFC 1808 Section 4)",
      "        if url.startswith(\"//\"):",
      "            parsed_rurl = urlparse(resp.url)",
      "            url = \":\".join([to_native_string(parsed_rurl.scheme), url])",
      "",
      "        # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)",
      "        parsed = urlparse(url)",
      "        if parsed.fragment == \"\" and previous_fragment:",
      "            parsed = parsed._replace(fragment=previous_fragment)",
      "        elif parsed.fragment:",
      "            previous_fragment = parsed.fragment",
      "        url = parsed.geturl()",
      "",
      "        # Facilitate relative 'location' headers, as allowed by RFC 7231.",
      "        # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')",
      "        # Compliant with RFC3986, we percent encode the url.",
      "        if not parsed.netloc:",
      "            url = urljoin(resp.url, requote_uri(url))",
      "        else:",
      "            url = requote_uri(url)",
      "",
      "        prepared_request.url = to_native_string(url)",
      "",
      "        self.rebuild_method(prepared_request, resp)",
      "",
      "        # https://github.com/psf/requests/issues/1084",
      "        if resp.status_code not in (",
      "            codes.temporary_redirect,",
      "            codes.permanent_redirect,",
      "        ):",
      "            # https://github.com/psf/requests/issues/3490",
      "            purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")",
      "            for header in purged_headers:",
      "                prepared_request.headers.pop(header, None)",
      "            prepared_request.body = None",
      "",
      "        headers = prepared_request.headers",
      "        headers.pop(\"Cookie\", None)",
      "",
      "        # Extract any cookies sent on the response to the cookiejar",
      "        # in the new request. Because we've mutated our copied prepared",
      "        # request, use the old one that we haven't yet touched.",
      "        extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)",
      "        merge_cookies(prepared_request._cookies, self.cookies)",
      "        prepared_request.prepare_cookies(prepared_request._cookies)",
      "",
      "        # Rebuild auth and proxy information.",
      "        proxies = self.rebuild_proxies(prepared_request, proxies)",
      "        self.rebuild_auth(prepared_request, resp)",
      "",
      "        # A failed tell() sets `_body_position` to `object()`. This non-None",
      "        # value ensures `rewindable` will be True, allowing us to raise an",
      "        # UnrewindableBodyError, instead of hanging the connection.",
      "        rewindable = prepared_request._body_position is not None and (",
      "            \"Content-Length\" in headers or \"Transfer-Encoding\" in headers",
      "        )",
      "",
      "        # Attempt to rewind consumed file-like object.",
      "        if rewindable:",
      "            rewind_body(prepared_request)",
      "",
      "        # Override the original request.",
      "        req = prepared_request",
      "",
      "        if yield_requests:",
      "            yield req",
      "        else:",
      "            resp = self.send(",
      "                req,",
      "                stream=stream,",
      "                timeout=timeout,",
      "                verify=verify,",
      "                cert=cert,",
      "                proxies=proxies,",
      "                allow_redirects=False,",
      "                **adapter_kwargs,",
      "            )",
      "",
      "            extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)",
      "",
      "            # extract redirect url, if any, for the next loop",
      "            url = self.get_redirect_target(resp)",
      "            yield resp"
    ],
    "test_cases": [
      {
        "id": 1,
        "test_name": "test_HTTP_302_ALLOW_REDIRECT_GET",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_HTTP_302_ALLOW_REDIRECT_GET",
        "test_code": [
          "def test_HTTP_302_ALLOW_REDIRECT_GET(self, httpbin):",
          "    r = requests.get(httpbin('redirect', '1'))",
          "    assert r.status_code == 200",
          "    assert r.history[0].status_code == 302",
          "    assert r.history[0].is_redirect"
        ]
      },
      {
        "id": 2,
        "test_name": "test_HTTP_307_ALLOW_REDIRECT_POST",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_HTTP_307_ALLOW_REDIRECT_POST",
        "test_code": [
          "def test_HTTP_307_ALLOW_REDIRECT_POST(self, httpbin):",
          "    r = requests.post(",
          "        httpbin('redirect-to'),",
          "        data='test',",
          "        params={'url': 'post', 'status_code': 307},",
          "    )",
          "    assert r.status_code == 200",
          "    assert r.history[0].status_code == 307",
          "    assert r.history[0].is_redirect",
          "    assert r.json()['data'] == 'test'"
        ]
      },
      {
        "id": 3,
        "test_name": "test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE",
        "test_code": [
          "def test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE(self, httpbin):",
          "    byte_str = b'test'",
          "    r = requests.post(",
          "        httpbin('redirect-to'),",
          "        data=io.BytesIO(byte_str),",
          "        params={'url': 'post', 'status_code': 307},",
          "    )",
          "    assert r.status_code == 200",
          "    assert r.history[0].status_code == 307",
          "    assert r.history[0].is_redirect",
          "    assert r.json()['data'] == byte_str.decode('utf-8')"
        ]
      },
      {
        "id": 4,
        "test_name": "test_HTTP_302_TOO_MANY_REDIRECTS",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_HTTP_302_TOO_MANY_REDIRECTS",
        "test_code": [
          "def test_HTTP_302_TOO_MANY_REDIRECTS(self, httpbin):",
          "    try:",
          "        requests.get(httpbin('relative-redirect', '50'))",
          "    except TooManyRedirects as e:",
          "        url = httpbin('relative-redirect', '20')",
          "        assert e.request.url == url",
          "        assert e.response.url == url",
          "        assert len(e.response.history) == 30",
          "    else:",
          "        pytest.fail('Expected redirect to raise TooManyRedirects but it did not')"
        ]
      },
      {
        "id": 5,
        "test_name": "test_fragment_maintained_on_redirect",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_fragment_maintained_on_redirect",
        "test_code": [
          "def test_fragment_maintained_on_redirect(self, httpbin):",
          "    fragment = '#view=edit&token=hunter2'",
          "    r = requests.get(httpbin('redirect-to?url=get') + fragment)",
          "    assert len(r.history) > 0",
          "    assert r.history[0].request.url == httpbin('redirect-to?url=get') + fragment",
          "    assert r.url == httpbin('get') + fragment"
        ]
      },
      {
        "id": 6,
        "test_name": "test_HTTP_200_OK_GET_WITH_PARAMS",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_HTTP_200_OK_GET_WITH_PARAMS",
        "test_code": [
          "def test_HTTP_200_OK_GET_WITH_PARAMS(self, httpbin):",
          "    heads = {'User-agent': 'Mozilla/5.0'}",
          "    r = requests.get(httpbin('user-agent'), headers=heads)",
          "    assert heads['User-agent'] in r.text",
          "    assert r.status_code == 200"
        ]
      },
      {
        "id": 7,
        "test_name": "test_manual_redirect_with_partial_body_read",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_manual_redirect_with_partial_body_read",
        "test_code": [
          "def test_manual_redirect_with_partial_body_read(self, httpbin):",
          "    s = requests.Session()",
          "    r1 = s.get(httpbin('redirect/2'), allow_redirects=False, stream=True)",
          "    assert r1.is_redirect",
          "    rg = s.resolve_redirects(r1, r1.request, stream=True)",
          "    # read only the first eight bytes of the response body, then follow the redirect",
          "    r1.iter_content(8)",
          "    r2 = next(rg)",
          "    assert r2.is_redirect",
          "    # read all of the response via iter_content, then follow the redirect",
          "    for _ in r2.iter_content():",
          "        pass",
          "    r3 = next(rg)",
          "    assert not r3.is_redirect"
        ]
      },
      {
        "id": 8,
        "test_name": "test_redirect_with_wrong_gzipped_header",
        "test_file": "requests/tests/test_requests.py",
        "test_nodeid": "requests/tests/test_requests.py::TestRequests::test_redirect_with_wrong_gzipped_header",
        "test_code": [
          "def test_redirect_with_wrong_gzipped_header(self, httpbin):",
          "    s = requests.Session()",
          "    url = httpbin('redirect/1')",
          "    # patch adapter to return a gzipped header once to exercise branch",
          "    self._patch_adapter_gzipped_redirect(s, url)",
          "    s.get(url)"
        ]
      }
    ],
    "fixtures": [
      "httpbin (local http test server)",
      "io (used by seekable body test)",
      "requests.Session (session used to exercise resolve_redirects)",
      "pytest (for assertions/parametrize)"
    ],
    "description": "Generator in SessionRedirectMixin that follows redirect responses. Handles relative/absolute locations, fragment preservation, cookie transfer, header purging, rewinding bodies, rebuilding proxies/auth, and max_redirects enforcement.",
    "security_focus": [
      "authorization_header_leakage_on_redirect",
      "cookie_handling_during_redirect",
      "body_rewind_and_unrewindable_checks",
      "redirect_loop_detection"
    ],
    "setup_notes": {
      "note": "These tests are end-to-end and rely on the httpbin fixture (and in one case a patched adapter). For unit tests, mock network/adapter behavior and construct Response/PreparedRequest objects to iterate resolve_redirects directly."
    }
  }
]
